{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0b4c0d",
   "metadata": {},
   "source": [
    "## Observability with Opik - LLM-Native Monitoring\n",
    "\n",
    "**Alternative Approach**: Instead of traditional observability tools (Prometheus, Grafana, Jaeger), we'll use **Opik** - an open-source LLM observability platform designed specifically for AI applications.\n",
    "\n",
    "### Why Opik for LLM Applications?\n",
    "\n",
    "**Traditional Tools (Prometheus/Grafana/Jaeger):**\n",
    "- Generic application monitoring\n",
    "- Manual instrumentation required\n",
    "- Separate tools for metrics, logs, traces\n",
    "- Limited LLM-specific insights\n",
    "\n",
    "**Opik:**\n",
    "- Built specifically for LLM applications\n",
    "- Automatic LangChain/LangGraph integration\n",
    "- Unified dashboard for traces, costs, evaluations\n",
    "- Prompt versioning and experimentation\n",
    "- Response quality monitoring\n",
    "- Token usage and cost tracking per request\n",
    "\n",
    "### What We'll Cover:\n",
    "\n",
    "1. **Setup Opik** - Installation and configuration\n",
    "2. **Automatic Tracing** - LangChain/LangGraph integration\n",
    "3. **Custom Annotations** - Add business context\n",
    "4. **Cost Tracking** - Monitor spending per user/contract type\n",
    "5. **Evaluation** - Score response quality\n",
    "6. **Dashboard** - View insights in Opik UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db384d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opik installed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.2.1 requires openai<2.0.0,>=1.40.0, but you have openai 2.8.1 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install Opik\n",
    "!pip install -q opik\n",
    "\n",
    "print(\"Opik installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdc4d0",
   "metadata": {},
   "source": [
    "## Part 1: Install and Setup Opik\n",
    "\n",
    "Opik provides LLM-native observability with automatic tracing for LangChain applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348fe607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opik imported\n",
      "   Version: 1.9.33\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "# Import Opik\n",
    "import opik\n",
    "from opik import track\n",
    "from opik.integrations.langchain import OpikTracer\n",
    "\n",
    "print(\"Opik imported\")\n",
    "print(f\"   Version: {opik.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb93d5d",
   "metadata": {},
   "source": [
    "### Configure Opik\n",
    "\n",
    "Opik can run in two modes:\n",
    "1. **Cloud Mode** - Free hosted service at app.comet.com/opik âœ… **RECOMMENDED**\n",
    "2. **Local Mode** - Self-hosted with Docker (limited SDK tracing support)\n",
    "\n",
    "**Important Note for Local Deployment:**\n",
    "The self-hosted Opik instance (via Docker) has limited automatic tracing capabilities. While your LLM calls will work correctly, you may see 404 errors for trace endpoints. For full automatic tracing features demonstrated in this notebook, we recommend using **Opik Cloud** (free tier available).\n",
    "\n",
    "**Alternative:** For production-grade observability with full local control, use the traditional stack in Notebook 02 (Prometheus + Grafana + Jaeger + OpenTelemetry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e087358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Configuration completed successfully. Traces will be logged to 'Default Project' project. To change the destination project, see: https://www.comet.com/docs/opik/tracing/log_traces#configuring-the-project-name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opik configured successfully!\n",
      "   Mode: Local (Self-Hosted)\n",
      "   UI: http://localhost:5173\n",
      "   Data stored in: ~/opik directory\n",
      "\n",
      "Configuration saved to: ~/.opik.config\n",
      "\n",
      "ðŸ’¡ To use Opik Cloud instead:\n",
      "   Run: opik.configure(use_local=False)\n",
      "   Sign up: https://www.comet.com/signup?from=opik\n"
     ]
    }
   ],
   "source": [
    "# Configure Opik for local deployment\n",
    "import opik\n",
    "\n",
    "# Option 1: Use Opik Cloud (RECOMMENDED for full features)\n",
    "# Sign up at: https://www.comet.com/signup?from=opik\n",
    "# opik.configure(use_local=False)\n",
    "# Then set your API key when prompted or via environment:\n",
    "# os.environ[\"OPIK_API_KEY\"] = \"your_api_key_here\"\n",
    "# os.environ[\"OPIK_WORKSPACE\"] = \"your_workspace\"\n",
    "\n",
    "# Option 2: Use local Opik instance (self-hosted)\n",
    "opik.configure(use_local=True)\n",
    "\n",
    "print(\"Opik configured successfully!\")\n",
    "print(f\"   Mode: Local (Self-Hosted)\")\n",
    "print(f\"   UI: http://localhost:5173\")\n",
    "print(f\"   Data stored in: ~/opik directory\")\n",
    "print(f\"\\nConfiguration saved to: ~/.opik.config\")\n",
    "print(f\"\\nðŸ’¡ To use Opik Cloud instead:\")\n",
    "print(f\"   Run: opik.configure(use_local=False)\")\n",
    "print(f\"   Sign up: https://www.comet.com/signup?from=opik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e90b9b",
   "metadata": {},
   "source": [
    "## Part 2: Automatic LangChain Tracing\n",
    "\n",
    "Opik automatically traces LangChain/LangGraph operations with zero manual instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b7ff6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain components imported\n"
     ]
    }
   ],
   "source": [
    "# Import LangChain components\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(Path.cwd().parent / \".env\", override=True)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "print(\"LangChain components imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133c24c",
   "metadata": {},
   "source": [
    "### Initialize Opik Tracer for LangChain\n",
    "\n",
    "The OpikTracer callback handler automatically captures all LangChain operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae92238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opik tracer initialized for LangChain\n",
      "   Project: contract-analysis\n",
      "   Tags: notebook, demo\n",
      "   OpikTracer(graph=app.get_graph(xray=True))\n",
      "\n",
      "ðŸ’¡ For LangGraph workflows, pass graph parameter:\n"
     ]
    }
   ],
   "source": [
    "# Create Opik callback handler for LangChain\n",
    "# Note: We'll add the graph parameter later when we create the LangGraph workflow\n",
    "opik_tracer = OpikTracer(\n",
    "    project_name=\"contract-analysis\",\n",
    "    tags=[\"notebook\", \"demo\"]\n",
    ")\n",
    "\n",
    "print(\"Opik tracer initialized for LangChain\")\n",
    "print(\"   Project: contract-analysis\")\n",
    "\n",
    "print(\"   Tags: notebook, demo\")\n",
    "print(\"   OpikTracer(graph=app.get_graph(xray=True))\")\n",
    "print(\"\\nðŸ’¡ For LangGraph workflows, pass graph parameter:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5462d86",
   "metadata": {},
   "source": [
    "### Simple Classification Example with Automatic Tracing\n",
    "\n",
    "Run a contract classification with automatic trace capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba0944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Started logging traces to the \"contract-analysis\" project at http://localhost:5173/api/v1/session/redirect/projects/?trace_id=019ace3f-7abd-79fe-bc87-84fb58b7e287&path=aHR0cDovL2xvY2FsaG9zdDo1MTczL2FwaS8=.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying contract with Opik tracing...\n",
      "\n",
      "Classification Complete:\n",
      "   Type: NDA\n",
      "   Complexity: Simple\n",
      "   Confidence: 90.00%\n",
      "   Reasoning: The contract is a straightforward Non-Disclosure Agreement with clear obligations and a defined term, making it simple in nature.\n",
      "\n",
      "Trace automatically sent to Opik!\n",
      "   View at: http://localhost:5173\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class ContractClassification(BaseModel):\n",
    "    contract_type: str = Field(description=\"Type: NDA, SaaS, Employment, Partnership, Unknown\")\n",
    "    complexity: str = Field(description=\"Complexity: Simple, Moderate, Complex\")\n",
    "    confidence_score: float = Field(description=\"Confidence 0-1\")\n",
    "    reasoning: str = Field(description=\"Brief explanation\")\n",
    "\n",
    "# Sample contract\n",
    "sample_contract = \"\"\"\n",
    "NON-DISCLOSURE AGREEMENT\n",
    "\n",
    "This Non-Disclosure Agreement is entered into as of January 1, 2024,\n",
    "by and between TechCorp Inc. and John Doe.\n",
    "\n",
    "1. CONFIDENTIAL INFORMATION\n",
    "The Receiving Party agrees to maintain confidentiality of all information\n",
    "disclosed by the Disclosing Party.\n",
    "\n",
    "2. OBLIGATIONS\n",
    "- Maintain confidentiality\n",
    "- Not disclose to third parties\n",
    "- Use only for authorized purposes\n",
    "\n",
    "3. TERM\n",
    "This Agreement remains in effect for 2 years.\n",
    "\"\"\"\n",
    "\n",
    "# Create LLM with structured output\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"),\n",
    "    temperature=0\n",
    ")\n",
    "structured_llm = llm.with_structured_output(ContractClassification)\n",
    "\n",
    "# Create prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert contract analyst. Classify contracts by type and complexity.\"),\n",
    "    (\"user\", \"Classify this contract:\\n\\n{contract_text}\")\n",
    "])\n",
    "\n",
    "# Create chain\n",
    "chain = prompt | structured_llm\n",
    "\n",
    "# Run with Opik tracing (automatically captures everything!)\n",
    "print(\"Classifying contract with Opik tracing...\\n\")\n",
    "\n",
    "result = chain.invoke(\n",
    "    {\"contract_text\": sample_contract},\n",
    "    config={\"callbacks\": [opik_tracer]}  # This enables automatic tracing!\n",
    ")\n",
    "\n",
    "print(f\"Classification Complete:\")\n",
    "print(f\"   Type: {result.contract_type}\")\n",
    "print(f\"   Complexity: {result.complexity}\")\n",
    "print(f\"   Confidence: {result.confidence_score:.2%}\")\n",
    "print(f\"   Reasoning: {result.reasoning}\")\n",
    "print(f\"\\nTrace automatically sent to Opik!\")\n",
    "print(f\"   View at: http://localhost:5173\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5015ed81",
   "metadata": {},
   "source": [
    "## Part 3: Custom Function Tracking\n",
    "\n",
    "Use the `@track` decorator to monitor custom functions and add business context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1dd1195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tracked operations...\n",
      "\n",
      "PDF extracted: 2 pages, 442 chars\n",
      "Validation: True\n",
      "\n",
      "All operations tracked in Opik!\n"
     ]
    }
   ],
   "source": [
    "from opik import track\n",
    "import time\n",
    "\n",
    "@track(\n",
    "    name=\"extract_pdf_text\",\n",
    "    project_name=\"contract-analysis\",\n",
    "    tags=[\"pdf\", \"extraction\"]\n",
    ")\n",
    "def extract_pdf_simulation(file_path: str, user_id: str):\n",
    "    \"\"\"Simulate PDF extraction with Opik tracking.\"\"\"\n",
    "    time.sleep(0.3)\n",
    "    return {\n",
    "        \"text\": sample_contract,\n",
    "        \"pages\": 2,\n",
    "        \"chars\": len(sample_contract)\n",
    "    }\n",
    "\n",
    "\n",
    "@track(\n",
    "    name=\"validate_contract\",\n",
    "    project_name=\"contract-analysis\",\n",
    "    tags=[\"security\", \"validation\"]\n",
    ")\n",
    "def validate_contract_simulation(contract_text: str, user_id: str):\n",
    "    \"\"\"Simulate security validation with tracking.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return {\n",
    "        \"valid\": True,\n",
    "        \"pii_detected\": False,\n",
    "        \"issues\": []\n",
    "    }\n",
    "\n",
    "\n",
    "# Run tracked functions\n",
    "print(\"Running tracked operations...\\n\")\n",
    "\n",
    "pdf_result = extract_pdf_simulation(\"nda_standard.pdf\", \"user-001\")\n",
    "print(f\"PDF extracted: {pdf_result['pages']} pages, {pdf_result['chars']} chars\")\n",
    "\n",
    "validation_result = validate_contract_simulation(sample_contract, \"user-001\")\n",
    "print(f\"Validation: {validation_result['valid']}\")\n",
    "\n",
    "print(f\"\\nAll operations tracked in Opik!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849fc1c",
   "metadata": {},
   "source": [
    "## Part 4: Integrate with LangGraph Agent\n",
    "\n",
    "Let's add Opik observability to our complete contract analysis workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "619de99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent components imported\n",
      "Tracked LangGraph nodes defined\n"
     ]
    }
   ],
   "source": [
    "# Import agent state\n",
    "from agent.state import ContractAnalysisState, create_initial_state\n",
    "from langgraph.graph import StateGraph, END\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Agent components imported\")\n",
    "\n",
    "# Define classification node with Opik tracking\n",
    "@track(\n",
    "    name=\"classify_contract_node\",\n",
    "    project_name=\"contract-analysis\",\n",
    "    tags=[\"langgraph\", \"classification\"]\n",
    ")\n",
    "def classify_contract_with_opik(state: ContractAnalysisState) -> ContractAnalysisState:\n",
    "    \"\"\"Classification node with Opik observability.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create LLM chain\n",
    "        llm = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"), temperature=0)\n",
    "        structured_llm = llm.with_structured_output(ContractClassification)\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are an expert contract analyst. Classify contracts.\"),\n",
    "            (\"user\", \"Classify:\\n\\n{contract_text}\")\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | structured_llm\n",
    "        \n",
    "        # Run with Opik tracing\n",
    "        result = chain.invoke(\n",
    "            {\"contract_text\": state['contract_text'][:4000]},\n",
    "            config={\"callbacks\": [opik_tracer]}\n",
    "        )\n",
    "        \n",
    "        # Update state\n",
    "        state['contract_type'] = result.contract_type\n",
    "        state['complexity'] = result.complexity\n",
    "        state['confidence_score'] = result.confidence_score\n",
    "        \n",
    "        print(f\"  Classified: {result.contract_type} ({result.confidence_score:.2%})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        state['errors'].append(f\"Classification error: {str(e)}\")\n",
    "        state['contract_type'] = \"Unknown\"\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "# Define analysis node with Opik tracking\n",
    "@track(\n",
    "    name=\"analyze_contract_node\",\n",
    "    project_name=\"contract-analysis\",\n",
    "    tags=[\"langgraph\", \"analysis\"]\n",
    ")\n",
    "def analyze_contract_with_opik(state: ContractAnalysisState) -> ContractAnalysisState:\n",
    "    \"\"\"Analysis node with Opik observability.\"\"\"\n",
    "    \n",
    "    # Simulate analysis\n",
    "    state['key_terms'] = [\n",
    "        {\"term\": \"Confidentiality\", \"importance\": \"High\"},\n",
    "        {\"term\": \"Term Length\", \"importance\": \"Medium\"}\n",
    "    ]\n",
    "    state['risks'] = [\n",
    "        {\"risk\": \"Broad definition of confidential info\", \"severity\": \"Medium\"}\n",
    "    ]\n",
    "    \n",
    "    print(f\"  Analysis: {len(state['key_terms'])} terms, {len(state['risks'])} risks\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"Tracked LangGraph nodes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b4ef52",
   "metadata": {},
   "source": [
    "### Create and Run Observed LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea638c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraph workflow created\n",
      "OpikTracer configured with LangGraph graph visualization\n",
      "\n",
      "Running contract analysis with Opik observability...\n",
      "================================================================================\n",
      "  Classified: NDA (90.00%)\n",
      "  Analysis: 2 terms, 1 risks\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Contract Type: NDA\n",
      "Complexity: Simple\n",
      "Confidence: 90.00%\n",
      "Key Terms: 2\n",
      "Trace ID: 019ace42-3d3f-75d8-88f0-cde1e28be666\n",
      "Risks: 1\n",
      "\n",
      "Full trace with graph visualization: http://localhost:5173\n"
     ]
    }
   ],
   "source": [
    "# Create workflow\n",
    "workflow = StateGraph(ContractAnalysisState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"classify\", classify_contract_with_opik)\n",
    "workflow.add_node(\"analyze\", analyze_contract_with_opik)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"classify\")\n",
    "workflow.add_edge(\"classify\", \"analyze\")\n",
    "workflow.add_edge(\"analyze\", END)\n",
    "\n",
    "# Compile\n",
    "contract_agent_opik = workflow.compile()\n",
    "\n",
    "print(\"LangGraph workflow created\")\n",
    "\n",
    "# Create OpikTracer with graph visualization (IMPORTANT for LangGraph)\n",
    "opik_tracer_langgraph = OpikTracer(\n",
    "    graph=contract_agent_opik.get_graph(xray=True),  # Enable graph visualization\n",
    "    project_name=\"contract-analysis\",\n",
    "    tags=[\"langgraph\", \"workflow\"]\n",
    ")\n",
    "\n",
    "print(\"OpikTracer configured with LangGraph graph visualization\")\n",
    "\n",
    "# Run the agent with Opik observability\n",
    "print(\"\\nRunning contract analysis with Opik observability...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create initial state\n",
    "initial_state = create_initial_state(\n",
    "    contract_text=sample_contract,\n",
    "    file_path=\"nda_standard.pdf\",\n",
    "    user_id=\"demo_user_opik\"\n",
    ")\n",
    "\n",
    "# Execute with OpikTracer callback\n",
    "final_state = contract_agent_opik.invoke(\n",
    "    initial_state,\n",
    "    config={\"callbacks\": [opik_tracer_langgraph]}  # Pass tracer as callback\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nContract Type: {final_state['contract_type']}\")\n",
    "print(f\"Complexity: {final_state['complexity']}\")\n",
    "print(f\"Confidence: {final_state['confidence_score']:.2%}\")\n",
    "\n",
    "print(f\"Key Terms: {len(final_state['key_terms'])}\")\n",
    "print(f\"Trace ID: {opik_tracer_langgraph.created_traces()[0].id if opik_tracer_langgraph.created_traces() else 'N/A'}\")\n",
    "\n",
    "print(f\"Risks: {len(final_state['risks'])}\")\n",
    "print(f\"\\nFull trace with graph visualization: http://localhost:5173\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ded7c",
   "metadata": {},
   "source": [
    "## Part 5: Cost Tracking and Token Usage\n",
    "\n",
    "Opik automatically tracks token usage and costs for OpenAI calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d346ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 10 analyses to track costs...\n",
      "\n",
      "  Classified: NDA (90.00%)\n",
      "  1. NDA             (User: user-2)\n",
      "  Classified: SaaS (90.00%)\n",
      "  2. SaaS            (User: user-3)\n",
      "  Classified: Employment (90.00%)\n",
      "  3. Employment      (User: user-1)\n",
      "  Classified: Partnership (85.00%)\n",
      "  4. Partnership     (User: user-2)\n",
      "  Classified: Unknown (70.00%)\n",
      "  5. Unknown         (User: user-3)\n",
      "  Classified: NDA (90.00%)\n",
      "  6. NDA             (User: user-1)\n",
      "  Classified: SaaS (90.00%)\n",
      "  7. SaaS            (User: user-2)\n",
      "  Classified: Employment (90.00%)\n",
      "  8. Employment      (User: user-3)\n",
      "  Classified: Partnership (85.00%)\n",
      "  9. Partnership     (User: user-1)\n",
      "  Classified: Unknown (70.00%)\n",
      "  10. Unknown         (User: user-2)\n",
      "\n",
      "All analyses tracked!\n",
      "View cost breakdown by:\n",
      "   â€¢ User ID\n",
      "   â€¢ Contract type\n",
      "   â€¢ Time period\n",
      "   â€¢ Model used\n",
      "\n",
      "Check Opik dashboard: http://localhost:5173\n"
     ]
    }
   ],
   "source": [
    "# Run multiple analyses to accumulate cost data\n",
    "print(\"Running 10 analyses to track costs...\\n\")\n",
    "\n",
    "contract_samples = [\n",
    "    \"NDA between TechCorp and vendor...\",\n",
    "    \"SaaS subscription agreement for cloud services...\",\n",
    "    \"Employment offer letter for software engineer...\",\n",
    "    \"Partnership agreement for joint venture...\",\n",
    "    \"Service Level Agreement for support services...\"\n",
    "]\n",
    "\n",
    "for i, sample in enumerate(contract_samples * 2, 1):  # 10 total\n",
    "    state = create_initial_state(\n",
    "        contract_text=sample,\n",
    "        file_path=f\"contract_{i}.pdf\",\n",
    "        user_id=f\"user-{i % 3 + 1}\"  # 3 different users\n",
    "    )\n",
    "    \n",
    "    result = classify_contract_with_opik(state)\n",
    "    print(f\"  {i}. {result['contract_type']:15} (User: {state['user_id']})\")\n",
    "\n",
    "print(f\"\\nAll analyses tracked!\")\n",
    "print(f\"View cost breakdown by:\")\n",
    "print(f\"   â€¢ User ID\")\n",
    "print(f\"   â€¢ Contract type\")\n",
    "print(f\"   â€¢ Time period\")\n",
    "print(f\"   â€¢ Model used\")\n",
    "print(f\"\\nCheck Opik dashboard: http://localhost:5173\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ec033",
   "metadata": {},
   "source": [
    "## Part 6: Response Evaluation\n",
    "\n",
    "Opik allows you to score and evaluate LLM responses for quality monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f40ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating classification quality...\n",
      "\n",
      "âœ“ Expected: NDA          | Got: NDA          | Confidence: 90.00%\n",
      "âœ“ Expected: SaaS         | Got: SaaS         | Confidence: 90.00%\n",
      "âœ“ Expected: Employment   | Got: Employment   | Confidence: 90.00%\n",
      "\n",
      "Overall Metrics:\n",
      "   Accuracy: 100.00%\n",
      "   Avg Confidence: 90.00%\n",
      "\n",
      "View detailed evaluation in Opik!\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation function\n",
    "@track(\n",
    "    name=\"evaluate_classification\",\n",
    "    project_name=\"contract-analysis\"\n",
    ")\n",
    "def evaluate_classification_quality(contract_text: str, expected_type: str):\n",
    "    \"\"\"Evaluate classification accuracy.\"\"\"\n",
    "    \n",
    "    # Run classification\n",
    "    llm = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"), temperature=0)\n",
    "    structured_llm = llm.with_structured_output(ContractClassification)\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Classify the contract type.\"),\n",
    "        (\"user\", \"{contract_text}\")\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | structured_llm\n",
    "    result = chain.invoke(\n",
    "        {\"contract_text\": contract_text},\n",
    "        config={\"callbacks\": [opik_tracer]}\n",
    "    )\n",
    "    \n",
    "    # Score the result\n",
    "    is_correct = result.contract_type == expected_type\n",
    "    confidence_score = result.confidence_score\n",
    "    \n",
    "    return {\n",
    "        \"expected\": expected_type,\n",
    "        \"predicted\": result.contract_type,\n",
    "        \"correct\": is_correct,\n",
    "        \"confidence\": confidence_score\n",
    "    }\n",
    "\n",
    "\n",
    "# Test evaluations\n",
    "print(\"Evaluating classification quality...\\n\")\n",
    "\n",
    "test_cases = [\n",
    "    (\"This NDA protects confidential information...\", \"NDA\"),\n",
    "    (\"SaaS subscription for monthly software access...\", \"SaaS\"),\n",
    "    (\"Employment contract for full-time position...\", \"Employment\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for contract, expected in test_cases:\n",
    "    result = evaluate_classification_quality(contract, expected)\n",
    "    status = \"âœ“\" if result['correct'] else \"âœ—\"\n",
    "    print(f\"{status} Expected: {result['expected']:12} | Got: {result['predicted']:12} | Confidence: {result['confidence']:.2%}\")\n",
    "    results.append(result)\n",
    "\n",
    "accuracy = sum(r['correct'] for r in results) / len(results)\n",
    "avg_confidence = sum(r['confidence'] for r in results) / len(results)\n",
    "\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"   Accuracy: {accuracy:.2%}\")\n",
    "print(f\"   Avg Confidence: {avg_confidence:.2%}\")\n",
    "print(f\"\\nView detailed evaluation in Opik!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb5eb75",
   "metadata": {},
   "source": [
    "## Part 7: Experiment Tracking\n",
    "\n",
    "Track different prompt versions and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9fdda30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different prompt strategies...\n",
      "\n",
      "  v1_basic        â†’ NDA          (Confidence: 90.00%)\n",
      "  v2_detailed     â†’ NDA          (Confidence: 90.00%)\n",
      "  v3_structured   â†’ NDA          (Confidence: 95.00%)\n",
      "\n",
      "Experiment results tracked!\n",
      "Compare prompts in Opik to find the best performer\n"
     ]
    }
   ],
   "source": [
    "# Test different prompt strategies\n",
    "prompts_to_test = {\n",
    "    \"v1_basic\": \"Classify this contract: {contract_text}\",\n",
    "    \n",
    "    \"v2_detailed\": \"\"\"Analyze this contract and classify it.\n",
    "Consider: legal language, parties involved, obligations, and termination clauses.\n",
    "Contract: {contract_text}\"\"\",\n",
    "    \n",
    "    \"v3_structured\": \"\"\"You are an expert legal analyst with 20 years experience.\n",
    "Carefully read the contract below and classify its type with reasoning.\n",
    "\n",
    "Contract Types:\n",
    "- NDA: Non-Disclosure Agreement\n",
    "- SaaS: Software as a Service\n",
    "- Employment: Offer letters, employment contracts\n",
    "- Partnership: Joint ventures, partnerships\n",
    "\n",
    "Contract:\n",
    "{contract_text}\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Testing different prompt strategies...\\n\")\n",
    "\n",
    "for version, prompt_template in prompts_to_test.items():\n",
    "    # Track each experiment\n",
    "    @track(\n",
    "        name=f\"prompt_experiment_{version}\",\n",
    "        project_name=\"contract-analysis\",\n",
    "        tags=[\"experiment\", version]\n",
    "    )\n",
    "    def test_prompt(template):\n",
    "        llm = ChatOpenAI(model=os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\"), temperature=0)\n",
    "        structured_llm = llm.with_structured_output(ContractClassification)\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a contract analyst.\"),\n",
    "            (\"user\", template)\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | structured_llm\n",
    "        result = chain.invoke(\n",
    "            {\"contract_text\": sample_contract},\n",
    "            config={\"callbacks\": [opik_tracer]}\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    result = test_prompt(prompt_template)\n",
    "    print(f\"  {version:15} â†’ {result.contract_type:12} (Confidence: {result.confidence_score:.2%})\")\n",
    "\n",
    "print(f\"\\nExperiment results tracked!\")\n",
    "print(f\"Compare prompts in Opik to find the best performer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eacb31",
   "metadata": {},
   "source": [
    "## Part 8: Starting Local Opik Instance\n",
    "\n",
    "To view all the traces and metrics we've been collecting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Start Local Opik Instance:\n",
    "\n",
    "1. Clone Opik repository (if not already done):\n",
    "   \n",
    "   git clone https://github.com/comet-ml/opik.git\n",
    "   cd opik\n",
    "\n",
    "2. Start Opik using Docker Compose:\n",
    "   \n",
    "   # Full Opik platform (recommended)\n",
    "   ./opik.sh\n",
    "   \n",
    "   # Or directly with docker compose:\n",
    "   cd deployment/docker-compose\n",
    "   docker compose --profile opik up --detach\n",
    "\n",
    "3. Configure Python SDK for local deployment:\n",
    "   \n",
    "   opik configure --use_local\n",
    "   \n",
    "   # Or in Python:\n",
    "   import opik\n",
    "   opik.configure(use_local=True)\n",
    "\n",
    "4. Access Opik UI:\n",
    "   \n",
    "   http://localhost:5173\n",
    "\n",
    "5. Data Storage:\n",
    "   \n",
    "   All data stored in: ~/opik directory\n",
    "   Config file: ~/.opik.config\n",
    "\n",
    "print(\"Instructions displayed above\")\n",
    "\n",
    "6. Stop Opik:\n",
    "\n",
    "\n",
    "   ./opik.sh --stop   â€¢ Advanced filters (user, tags, etc.)\n",
    "\n",
    "   â€¢ Quality Evaluations\n",
    "\n",
    "7. Alternative: Use Opik Cloud (Recommended for full features)   â€¢ Prompt Version comparison\n",
    "\n",
    "      â€¢ Cost Dashboard with breakdowns\n",
    "\n",
    "   - Sign up: https://www.comet.com/signup?from=opik   â€¢ Token Usage tracking per request\n",
    "\n",
    "   - Configure: opik.configure(use_local=False)   â€¢ Trace Timeline with LangGraph visualization\n",
    "\n",
    "   - Enter API key when promptedFeatures in Opik UI:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1717162a",
   "metadata": {},
   "source": [
    "## Comparison: Opik vs Traditional Stack\n",
    "\n",
    "Understanding when to use each approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79127f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = \"\"\"\n",
    "TRADITIONAL STACK (Prometheus/Grafana/Jaeger)\n",
    "Pros:\n",
    "  - Industry standard, well-established\n",
    "  - Great for infrastructure monitoring\n",
    "  - Flexible, customizable dashboards\n",
    "  - Good for multi-service architectures\n",
    "\n",
    "Cons:\n",
    "  - Requires manual instrumentation for LLM calls\n",
    "  - No built-in cost tracking\n",
    "  - No prompt versioning\n",
    "  - Separate tools for different concerns\n",
    "  - Complex setup (3+ services)\n",
    "\n",
    "OPIK\n",
    "Pros:\n",
    "  - Zero-config LangChain/LangGraph integration\n",
    "  - Automatic token and cost tracking\n",
    "  - Built-in prompt experimentation\n",
    "  - Unified dashboard for everything\n",
    "  - LLM-specific metrics (hallucination, response quality)\n",
    "  - Single service deployment\n",
    "\n",
    "Cons:\n",
    "  - Newer, less mature ecosystem\n",
    "  - Focused on LLM apps (not general purpose)\n",
    "  - Limited customization vs Grafana\n",
    "\n",
    "WHEN TO USE EACH:\n",
    "\n",
    "Use Traditional Stack When:\n",
    "  - You need infrastructure-level monitoring\n",
    "  - Multi-language, multi-service architecture\n",
    "  - Existing Prometheus/Grafana expertise\n",
    "  - Custom metric aggregation requirements\n",
    "\n",
    "Use Opik When:\n",
    "  - Primary focus is LLM application monitoring\n",
    "  - Need cost tracking per user/request\n",
    "  - Want prompt A/B testing\n",
    "  - Rapid prototyping and iteration\n",
    "  - Simpler setup and maintenance\n",
    "\"\"\"\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90146151",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Automatic Tracing**\n",
    "   - Zero-config LangChain integration via callbacks\n",
    "   - Automatic token counting and cost calculation\n",
    "   - Full request/response capture\n",
    "\n",
    "2. **Custom Tracking**\n",
    "   - `@track` decorator for any function\n",
    "   - Rich metadata logging\n",
    "   - Business context capture\n",
    "\n",
    "3. **Cost Monitoring**\n",
    "   - Per-user, per-model, per-operation costs\n",
    "   - Token usage trends\n",
    "   - Budget alerts (in Opik UI)\n",
    "\n",
    "4. **Quality Evaluation**\n",
    "   - Score responses for accuracy\n",
    "   - Track confidence over time\n",
    "   - Identify low-quality outputs\n",
    "\n",
    "5. **Experimentation**\n",
    "   - Compare prompt versions\n",
    "   - A/B test different approaches\n",
    "   - Find optimal configurations\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
