{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f885d1",
   "metadata": {},
   "source": [
    "### Conversation Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d99deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_deployment = os.getenv(\"AZURE_DEPLOYMENT_NAME\")\n",
    "azure_api_version = os.getenv(\"AZURE_API_VERSION\")\n",
    "\n",
    "if not azure_endpoint or not azure_api_key or not azure_deployment or not azure_api_version:\n",
    "    raise ValueError(\"Azure OpenAI environment variables are not set.\")\n",
    "\n",
    "temperature = 0.7\n",
    "max_tokens = 1500\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_api_key,\n",
    "    azure_deployment=azure_deployment,\n",
    "    api_version=azure_api_version,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9069003",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are a chatbot that is helpful.\n",
    "    Your goal is to help the user and makes also jokes.\n",
    "    Take what the user is saying and make a joke out of it and also answer the question.\n",
    "    \n",
    "    {conversation_history}\n",
    "    \n",
    "    {additional_information}\n",
    "    \n",
    "    Human: {human_input}\n",
    "    Chatbot:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"conversation_history\", \"human_input\", \"additional_information\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"conversation_history\",\n",
    "    input_key=\"human_input\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72654468",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(\n",
    "    human_input=\"Is pear a fruit or vegetable?\",\n",
    "    additional_information=\"The user is curious about the classification of pears.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(\n",
    "    human_input=\"what was one of the fruits I first asked you about?\",\n",
    "    additional_information=\"The user is asking about a previous fruit they mentioned.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee829af",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.predict(\n",
    "    human_input=\"which party won the General Elections in India in the year 2014?\",\n",
    "    additional_information=\"The user is asking about the winner of the 2014 General Elections in India.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
