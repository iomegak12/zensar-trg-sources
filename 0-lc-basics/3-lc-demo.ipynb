{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7c469e8",
   "metadata": {},
   "source": [
    "### LangChain Basics - Complex / Multiple Chains (LCEL Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aad369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import LLMChain, SequentialChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf73d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_deployment = os.getenv(\"AZURE_DEPLOYMENT_NAME\")\n",
    "azure_api_version = os.getenv(\"AZURE_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ddfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=azure_api_key,\n",
    "    azure_deployment=azure_deployment,\n",
    "    api_version=azure_api_version,\n",
    "    temperature=0.0,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5727ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"\n",
    "    You're a helpful assistant, who has good and proficient english writing skills.\n",
    "    Write a Blog Outline for the following topic:\n",
    "    Topic: {topic}\n",
    "\"\"\"\n",
    "\n",
    "template2 = \"\"\"\n",
    "    You're a helpful assistant, who has good and proficient english writing skills.\n",
    "    Write a Blog Post based on the following outline:\n",
    "    Outline: {outline}\n",
    "\"\"\"\n",
    "\n",
    "template3 = \"\"\"\n",
    "    You're a helpful assistant, who has good and proficient language skills including Translating.\n",
    "    \n",
    "    Translate the following text to Marathi language:\n",
    "    {blog_post}\n",
    "\"\"\"\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=template1\n",
    ")\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=[\"outline\"],\n",
    "    template=template2\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    input_variables=[\"blog_post\"],\n",
    "    template=template3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24801c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create LCEL chains using the pipe operator\n",
    "# chain1 = prompt1 | llm\n",
    "# chain2 = prompt2 | llm\n",
    "# chain3 = prompt3 | llm\n",
    "\n",
    "# # Combine chains using LCEL pipe operators\n",
    "# sequential_chain = (\n",
    "#     {\"topic\": RunnablePassthrough()}\n",
    "#     | {\"outline\": chain1}\n",
    "#     | {\"outline\": lambda x: x[\"outline\"].content, \"blog_post\": chain2}\n",
    "#     | {\"outline\": lambda x: x[\"outline\"], \"blog_post\": lambda x: x[\"blog_post\"].content, \"translated_text\": chain3}\n",
    "#     | {\"outline\": lambda x: x[\"outline\"], \"blog_post\": lambda x: x[\"blog_post\"], \"translated_text\": lambda x: x[\"translated_text\"].content}\n",
    "# )\n",
    "\n",
    "chain1 = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt1,\n",
    "    output_key=\"outline\"\n",
    ")\n",
    "\n",
    "chain2 = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt2,\n",
    "    output_key=\"blog_post\"\n",
    ")\n",
    "\n",
    "chain3 = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt3,\n",
    "    output_key=\"translated_text\"\n",
    ")\n",
    "\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[chain1, chain2, chain3],\n",
    "    input_variables=[\"topic\"],\n",
    "    output_variables=[\"outline\", \"blog_post\", \"translated_text\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sequential_chain.invoke({\"topic\": \"Zensar AI For Leaders Program\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d987f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outline:\")\n",
    "print(response[\"outline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b91e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBlog Post:\")\n",
    "print(response[\"blog_post\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTranslated Text:\")\n",
    "print(response[\"translated_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
